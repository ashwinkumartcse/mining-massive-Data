{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "3BWGDO6AXTGG",
    "outputId": "eed4bacc-79cb-4158-d5ae-b85dae6f48b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (2.4.5)\n",
      "Requirement already satisfied: py4j==0.10.7 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.7)\n",
      "openjdk-8-jdk-headless is already the newest version (8u252-b09-1~18.04).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# Installation of pyspark \n",
    "!pip install pyspark\n",
    "!pip install -U -q PyDrive\n",
    "!apt install openjdk-8-jdk-headless -qq\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xgEunuUtmIC8"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "sc = SparkContext(appName=\"PythonKMeansOnIris\") \n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "67Val_BcoVk8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pickle \n",
    "import sys \n",
    "import time\n",
    "from numpy.linalg import norm \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "id": "bqJ1I9_Vm4oP",
    "outputId": "f01194f9-6ffb-4bab-f9c9-7d9074717edf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+--------+------+\n",
      "|       Date/Time|    Lat|     Lon|  Base|\n",
      "+----------------+-------+--------+------+\n",
      "|5/1/2014 0:02:00|40.7521|-73.9914|B02512|\n",
      "|5/1/2014 0:06:00|40.6965|-73.9715|B02512|\n",
      "|5/1/2014 0:15:00|40.7464|-73.9838|B02512|\n",
      "|5/1/2014 0:17:00|40.7463|-74.0011|B02512|\n",
      "|5/1/2014 0:17:00|40.7594|-73.9734|B02512|\n",
      "|5/1/2014 0:20:00|40.7685|-73.8625|B02512|\n",
      "|5/1/2014 0:21:00|40.7637|-73.9962|B02512|\n",
      "|5/1/2014 0:21:00|40.7252|-74.0023|B02512|\n",
      "|5/1/2014 0:25:00|40.7607|-73.9625|B02512|\n",
      "|5/1/2014 0:25:00|40.7212|-73.9879|B02512|\n",
      "|5/1/2014 0:29:00|40.7255|-73.9986|B02512|\n",
      "|5/1/2014 0:32:00|40.6467|-73.7901|B02512|\n",
      "|5/1/2014 0:40:00|40.7613|-73.9788|B02512|\n",
      "|5/1/2014 0:56:00|40.7807|-73.9497|B02512|\n",
      "|5/1/2014 1:00:00|40.7585|-73.9708|B02512|\n",
      "|5/1/2014 1:02:00|40.7163|-73.9895|B02512|\n",
      "|5/1/2014 1:06:00|40.7265|-73.9958|B02512|\n",
      "|5/1/2014 1:13:00|40.7559|-73.9867|B02512|\n",
      "|5/1/2014 1:13:00|40.7671|-73.9956|B02512|\n",
      "|5/1/2014 1:20:00|40.7707|-73.9944|B02512|\n",
      "+----------------+-------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'hdfs://localhost:9000/uber.csv'\n",
    "spdf = sqlContext.read.csv(path, header=True) # requires spark 2.0\n",
    "spdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/1/2014 0:02:00</td>\n",
       "      <td>40.7521</td>\n",
       "      <td>-73.9914</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/1/2014 0:06:00</td>\n",
       "      <td>40.6965</td>\n",
       "      <td>-73.9715</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/1/2014 0:15:00</td>\n",
       "      <td>40.7464</td>\n",
       "      <td>-73.9838</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/1/2014 0:17:00</td>\n",
       "      <td>40.7463</td>\n",
       "      <td>-74.0011</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/1/2014 0:17:00</td>\n",
       "      <td>40.7594</td>\n",
       "      <td>-73.9734</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date/Time      Lat       Lon    Base\n",
       "0  5/1/2014 0:02:00  40.7521  -73.9914  B02512\n",
       "1  5/1/2014 0:06:00  40.6965  -73.9715  B02512\n",
       "2  5/1/2014 0:15:00  40.7464  -73.9838  B02512\n",
       "3  5/1/2014 0:17:00  40.7463  -74.0011  B02512\n",
       "4  5/1/2014 0:17:00  40.7594  -73.9734  B02512"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spdf.toPandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "colab_type": "code",
    "id": "tKYWpI6b2Mi5",
    "outputId": "7621695b-e87f-4f01-b2fd-f8ba736b7b8b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/1/2014 0:02:00</td>\n",
       "      <td>40.7521</td>\n",
       "      <td>-73.9914</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/1/2014 0:06:00</td>\n",
       "      <td>40.6965</td>\n",
       "      <td>-73.9715</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/1/2014 0:15:00</td>\n",
       "      <td>40.7464</td>\n",
       "      <td>-73.9838</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/1/2014 0:17:00</td>\n",
       "      <td>40.7463</td>\n",
       "      <td>-74.0011</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/1/2014 0:17:00</td>\n",
       "      <td>40.7594</td>\n",
       "      <td>-73.9734</td>\n",
       "      <td>B02512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date/Time      Lat       Lon    Base\n",
       "0  5/1/2014 0:02:00  40.7521  -73.9914  B02512\n",
       "1  5/1/2014 0:06:00  40.6965  -73.9715  B02512\n",
       "2  5/1/2014 0:15:00  40.7464  -73.9838  B02512\n",
       "3  5/1/2014 0:17:00  40.7463  -74.0011  B02512\n",
       "4  5/1/2014 0:17:00  40.7594  -73.9734  B02512"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis=0,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 743
    },
    "colab_type": "code",
    "id": "4e6CQYhgoq8d",
    "outputId": "b381c5ab-ca59-4ded-9a14-8305266ce3cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B02512', array([ 40.7521, -73.9914]))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_data(row):\n",
    "    return (row[3],np.concatenate([(float(row[1]),), (float(row[2]),)]))\n",
    "rdd = sc.parallelize([parse_data(row[1]) for row in df.iterrows()])\n",
    "rdd.take(1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wa8AaacAuyB5"
   },
   "outputs": [],
   "source": [
    "# Number of centroids\n",
    "K = 3  \n",
    "# Number of K-means runs that are executed in parallel. Equivalently, number of sets of initial points\n",
    "RUNS = 1  \n",
    "# For reproducability of results\n",
    "RANDOM_SEED = 6000 \n",
    "# The K-means algorithm is terminated when the change in the \n",
    "# location of the centroids is smaller than 0.1\n",
    "converge_dist = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jTVF0VP3u9Uo"
   },
   "outputs": [],
   "source": [
    "#Utility Functions\n",
    "def print_log(s):\n",
    "    '''\n",
    "    Print progress logs\n",
    "    '''\n",
    "    sys.stdout.write(s + \"\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def compute_entropy(d):\n",
    "    '''\n",
    "    Compute the entropy given the frequency vector `d`\n",
    "    '''\n",
    "    d = np.array(d)\n",
    "    d = 1.0 * d / d.sum()\n",
    "    return -np.sum(d * np.log2(d))\n",
    "\n",
    "\n",
    "def choice(p):\n",
    "    '''\n",
    "    Generates a random sample from [0, len(p)),\n",
    "    where p[i] is the probability associated with i. \n",
    "    '''\n",
    "    random = np.random.random()\n",
    "    r = 0.0\n",
    "    for idx in range(len(p)):\n",
    "        r = r + p[idx]\n",
    "        if r > random:\n",
    "            return idx\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O_kgWwRVvC6y"
   },
   "outputs": [],
   "source": [
    "#Initialization of Centroids\n",
    "from operator import add\n",
    "def kmeans_init(rdd, K, RUNS, seed):\n",
    "    '''\n",
    "    Select `RUNS` sets of initial points for `K`-means++\n",
    "    '''\n",
    "    # the `centers` variable is what we want to return\n",
    "    n_data = rdd.count()\n",
    "    shape = rdd.take(1)[0][1].shape[0]\n",
    "    centers = np.zeros((RUNS, K, shape))\n",
    "    def update_dist(vec, dist, k):\n",
    "        new_dist = norm(vec - centers[:, k], axis=1)**2\n",
    "        return np.min([dist, new_dist], axis=0)\n",
    "    # The second element `dist` in the tuple below is the\n",
    "    # closest distance from each data point to the selected\n",
    "    # points in the initial set, where `dist[i]` is the\n",
    "    # closest distance to the points in the i-th initial set\n",
    "    data = (rdd\n",
    "            .map(lambda p: (p, [np.inf] * RUNS)) \\\n",
    "            .cache())\n",
    "    # Collect the feature vectors of all data points\n",
    "    # beforehand, might be useful in the following\n",
    "    # for-loop\n",
    "    local_data = (rdd\n",
    "                    .map(lambda t: t[1])\n",
    "                    .collect())\n",
    "    # Randomly select the first point for every run of\n",
    "    # k-means++, i.e. randomly select `RUNS` points\n",
    "    # and add it to the `centers` variable\n",
    "    sample = [local_data[k] for k in\n",
    "        np.random.randint(0, len(local_data), RUNS)]\n",
    "    centers[:, 0] = sample\n",
    "    for idx in range(K - 1):\n",
    "        ########################################################\n",
    "        # In each iteration, you need to select one point for\n",
    "        # each set of initial points (so select `RUNS` points\n",
    "        # in total). For each data point x, let D_i(x) be the\n",
    "        # distance between x and the nearest center that has\n",
    "        # already been added to the i-th set. Choose a new\n",
    "        # data point for i-th set using a weighted probability\n",
    "        # where point x is chosen with probability proportional\n",
    "        # to D_i(x)^2 . Repeat each data point by 25 times\n",
    "        # (for each RUN) to get 12140x25\n",
    "        ########################################################\n",
    "        #Update distance\n",
    "        data = (data\n",
    "            .map(lambda t:\n",
    "                    ((t[0][0],t[0][1]),update_dist(t[0][1],t[1],idx)))\n",
    "            .cache())\n",
    "        #print(data.take(1)[1].shape[1])\n",
    "        #Calculate sum of D_i(x)^2\n",
    "        d1 = data.map(lambda t: (1,t[1]))\n",
    "        d2 = d1.reduceByKey(lambda x,y: np.sum([x,y], axis=0))\n",
    "        total = d2.collect()[0][1]\n",
    "        #Normalize each distance to get the probabilities and\n",
    "        #reshapte to 12140x25\n",
    "        prob = (data\n",
    "            .map(lambda t:\n",
    "                np.divide(t[1],total))\n",
    "            .collect())\n",
    "        print(prob)\n",
    "        prob = np.reshape(prob,(len(local_data), RUNS))\n",
    "        #K'th centroid for each run\n",
    "        data_id = [choice(prob[:,i]) for i in xrange(RUNS)]\n",
    "        sample = [local_data[i] for i in data_id]\n",
    "        centers[:, idx+1] = sample\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yl7k-FmGvSj_"
   },
   "outputs": [],
   "source": [
    "#KMeans++ Function\n",
    "def get_closest(p, centers):\n",
    "    '''\n",
    "    Return the indices the nearest centroids of `p`.\n",
    "    `centers` contains sets of centroids, where `centers[i]` is\n",
    "    the i-th set of centroids.\n",
    "    '''\n",
    "    best = [0] * len(centers)\n",
    "    closest = [np.inf] * len(centers)\n",
    "    for idx in range(len(centers)):\n",
    "        for j in range(len(centers[0])):\n",
    "            temp_dist = norm(p - centers[idx][j])\n",
    "            if temp_dist < closest[idx]:\n",
    "                closest[idx] = temp_dist\n",
    "                best[idx] = j\n",
    "    return best\n",
    "\n",
    "\n",
    "def kmeans(rdd, K, RUNS, converge_dist, seed):\n",
    "    '''\n",
    "    Run K-means++ algorithm on `rdd`, where `RUNS` is the number of\n",
    "    initial sets to use.\n",
    "    '''\n",
    "    k_points = kmeans_init(rdd, K, RUNS, seed)\n",
    "    print_log(\"Initialized.\")\n",
    "    temp_dist = 1.0\n",
    "\n",
    "    iters = 0\n",
    "    st = time.time()\n",
    "    while temp_dist > converge_dist: \n",
    "        # Update all `RUNS` sets of centroids using standard k-means \n",
    "        # algorithm\n",
    "        # Outline:\n",
    "        #   - For each point x, select its nearest centroid in i-th \n",
    "        # centroids set\n",
    "        #   - Average all points that are assigned to the same \n",
    "        # centroid\n",
    "        #   - Update the centroid with the average of all points \n",
    "        # that are assigned to it\n",
    "        temp_dist = np.max([\n",
    "                np.sum([norm(k_points[idx][j] - new_points[(idx, \n",
    "                    j)]) for idx,j in new_points.keys()])\n",
    "                            ])\n",
    "\n",
    "        iters = iters + 1\n",
    "        if iters % 5 == 0:\n",
    "            print_log(\"Iteration %d max shift: %.2f (time: %.2f)\" %\n",
    "                      (iters, temp_dist, time.time() - st))\n",
    "            st = time.time()\n",
    "\n",
    "        # update old centroids\n",
    "        # You modify this for-loop to meet your need\n",
    "        for ((idx, j), p) in new_points.items():\n",
    "            k_points[idx][j] = p\n",
    "\n",
    "    return k_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Cj8WL0mrw60R",
    "outputId": "91aa73fe-c9f0-4d1c-ad70-380ccee67333",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-02b6372f1c18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRANDOM_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRUNS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverge_dist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_closest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m            \u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-43e7a9666d16>\u001b[0m in \u001b[0;36mkmeans\u001b[0;34m(rdd, K, RUNS, converge_dist, seed)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0minitial\u001b[0m \u001b[0msets\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     '''\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mk_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRUNS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initialized.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtemp_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-9aaa03084a4c>\u001b[0m in \u001b[0;36mkmeans_init\u001b[0;34m(rdd, K, RUNS, seed)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRUNS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m#K'th centroid for each run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mdata_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRUNS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlocal_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mcenters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xrange' is not defined"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "centroids = kmeans(rdd, K, RUNS, converge_dist,np.random.randint(1000))\n",
    "group = rdd.mapValues(lambda p: get_closest(p, centroids)) \\\n",
    "           .collect()\n",
    "\n",
    "print(\"Time takes to converge:\", time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost(rdd, centers):\n",
    "    '''\n",
    "    Compute the square of l2 norm from each data point in `rdd`\n",
    "    to the centroids in `centers`\n",
    "    '''\n",
    "    def _get_cost(p, centers):\n",
    "        best = [0] * len(centers)\n",
    "        closest = [np.inf] * len(centers)\n",
    "        for idx in range(len(centers)):\n",
    "            for j in range(len(centers[0])):\n",
    "                temp_dist = norm(p - centers[idx][j])\n",
    "                if temp_dist < closest[idx]:\n",
    "                    closest[idx] = temp_dist\n",
    "                    best[idx] = j\n",
    "        return np.array(closest)**2\n",
    "    \n",
    "    cost = rdd.map(lambda (name, v): _get_cost(v, \n",
    "           centroids)).collect()\n",
    "    return np.array(cost).sum(axis=0)\n",
    "\n",
    "cost = get_cost(rdd, centroids)\n",
    "log2 = np.log2print \"Min Cost:\\t\"+str(log2(np.max(cost)))\n",
    "print \"Max Cost:\\t\"+str(log2(np.min(cost)))\n",
    "print \"Mean Cost:\\t\"+str(log2(np.mean(cost)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "KMeans++PySpark.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
